---

title: "Homotopies"
description: "Lecture 2 in Algebraic Topology."
image: "/img/pics/IMG_4768.jpg"
writer: Aathreya Kadambi
lecturer: Professor Alexander Givental and Fomenko and Fuchs
date: "September 3, 2024"
---

It turns out that we are not just interested in spaces of continuous maps, but we are concerned with path-connected components of these spaces, or like things that are continuous but also can deform the thing.

Consider the maps $X \xrightarrow{f_1} Y$ and $X \xrightarrow{f_0} Y$. We say $f_0 \sim f_1$ are homotopic if there is some $F : X \times I  \rightarrow Y$ such that $F(x,0) = f_0$, $F(x,1) = f_1$.

<center>$$\pi(X,Y) = C(X,Y)/\sim$$</center>
we can consider homotopy classes of maps $X \rightarrow Y$. We get path-connected components or something (maybe homotopies parition any set into classes of path connected components or something).  

The classic example to distinguish path connectedness and connectedness is the union of $\sin(1/x)$ and the $y$-axis, which is supposedly connected but not path connected.

We say that $X$ and $Y$ are homotopy equivalent if $g \circ f \sim \text{id}_X$ (homotopic to the identity on $X$), and $f \circ g \sim \text{id}_Y$.

We define a ***retraction*** $r : X \twoheadrightarrow A\subseteq X$ so that $r|_A = \text{id}_A$. A retraction is ***deformational*** if $i \circ r \sim \text{id}_X$. Strict if the homotopy is identical on $A$, like for example, $A$ doesn't rotate or something during the retraction and stuff. In other words, strict means that $A$ doesn't move during the retraction. Apparently there are some pathological examples, for which one can refer to the book.

<div class="theorem">
**Proposition.** Deformation retraction is a homotopy equivalence.
</div>
*Proof.*

$i \circ r \sim \text{id}_X$, $r \circ i = \text{id}_A$.

Now $X$ is called ***contractible*** if $x_0 \in X$ is a deformtaional retraction of $X$.

<div class="theorem">
**Proposition.** $X$ is contractible is equivalent to $X \sim \text{pt}$. 
</div>

<div class="remark">
**Remark.** There is some result that we will eventually discuss called Borsuk or something about extending retractions or something.
</div>

There is a classification of homotopies or something:

<div class="theorem">
**Theorem.** TFAE (the following are equivalent):
1. $X \sim Y$
2. $\forall Z$, $\exists \alpha^Z : \pi(X,Z) \rightarrow \pi(Y, Z)$ which is natural with respect to $Z$, meaning that for any $\psi : Z \rightarrow W$, then whenever we have a map from $X$ to $Z$, we can compose it with a map from $Z$ to $W$ to get a map from $X$ to $W$ or something? More like in the sense that $\pi(X,Z) \rightarrow \pi(X,W)$ there is a map $\psi_*$ induced by $\psi$. And there is also a map $\psi_*$ from $\pi(Y,Z)$ to $\pi(Y,W)$. In between we have two bijections, and it commutes. Just naturality from category theory, but not sure how the naturality idea is motivated from anything right now.
3. $\forall Z$, $\exists \beta_Z : \pi(Z,X) \rightarrow \pi(Z,Y)$ which is a bijection which is natural with respect to $Z$. 
</div>
<i>Proof.</i>

We start by showing that 1 implies 3.  If $X \sim Y$, then there exist maps $f : X \rightarrow Y$ and $g : Y \rightarrow X$ such that the compositions are identity. Then we get maps:
<center>$$\pi(Z, X) \xrightarrow{f_*} \pi(Z,Y) \xrightarrow{g_*} \pi(Z,X)$$</center>
and the composition is identity. You can also do this in the opposite order and get identity. Therefore, the maps are set-theoretic inverses and so these are bijections.

<div class="strat">
**Strat.** Many things in mathematics relating to associativity come down to associativity of maps, for example associativity of vector addition comes from that of maps by thinking of vectors as translation maps. Apparently that comes in here too. He drew a square with $\pi(Z,X)$, $\pi(Z,Y)$, $\pi(W,X)$, and $\pi(Z,Y)$.
</div>

Now we can do the direction that 3 implies 1. For this direction, he started by taking the image of the identity of $\pi(X,X)$ in $\pi(X,Y)$ under the map $\beta_X$ which was defined previously as $f_*$ I think (so that $\beta_X(id) = f$). Awesome proof using the square $\pi(X,X)$, $\pi(X,Y)$, $\pi(Y,X)$, $\pi(Y,Y)$ basically by tracing where the elements $\text{id}_X$ and $\text{id}_Y$ go to throughout the diagram. We then do a similar square for the other way.

<div class="remark">
**Remark.** There is also a basepoint version of this, where we define $\pi_b(x,y)$ similarly to $\pi$ above. Another remark is 
<center>$$\pi_b(\Sigma X, Y) = \pi_b(X, \Omega Y)$$</center>
We can essentially think of these $C$ or $\pi_b$ or $\pi$ or whatever as functors, and so we see that $\Sigma$ and $\Omega$ are sort of adjoint. It is also important to note that they are not just functors to sets, they have some algebraic structure because loops can be adjoined, you can combine two loops to get another loop. I should note he put strikethroughs through the $b$s in $\pi_b$ but I am not completely sure why. Something like this is in Fuchs Chapter 4. Apparently Fuchs makes two errors in each of his lectures.
</div>